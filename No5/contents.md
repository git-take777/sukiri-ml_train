## pandas 活用

- データ準備と前処理
  - カテゴリーデータの個数集計数
  - データに欠損があった場合の基本的な対処法
  - 列ごとの代表値の計算法
- モデルの学習
  - 決定木による分類の概要
  - scikit-learn ライブラリによる決定木の学習法
- モデルの評価
  - 未知の入力データを用いた予測性能の評価法
  - 決定木の図示化




# 機械学習モデル評価の完全ガイド

## 🎯 なぜモデル評価が重要なのか？

### 問題の核心
- **見かけ上の高い正解率**に騙されてはいけない
- **同じ問題集を何度も解いて95点取れた**としても、**初めて見る問題では全然解けない**可能性
- 機械学習でも同じ問題が発生する（**過学習**）

### 正しいモデル評価の必要性
- **真の性能**を測定するため
- **未知のデータ**への対応力を確認するため
- **過学習**を防ぐため
- **実際のサービスで使える信頼できるモデル**を作るため

## 📊 正しいデータの分割方法（ホールドアウト法）

### 基本的な考え方
```
全データ = 訓練データ + テストデータ
```

### 分割の目的
- **訓練データ**: モデルに学習させるデータ（教科書的役割）
- **テストデータ**: モデルの実力を測るデータ（本番試験的役割）

### 実際の分割比率とコード
```python
# 一般的な分割例
x_train, x_test, y_train, y_test = train_test_split(
    x, y, 
    test_size=0.3,  # 30%をテスト用に
    random_state=0  # 再現性のため
)
```

### train_test_split関数の詳細
```python
train_test_split(特徴量, 正解データ, test_size=●, random_state=▲)
```

**パラメータの意味:**
- **特徴量**: 予測に使う入力データ（例：身長、体重、年齢など）
- **正解データ**: 予測したい答え（例：病気の有無、商品の売上など）
- **test_size**: テストデータの割合（0.3 = 30%）
- **random_state**: 乱数のシード値（再現性を保つため）

### 実行結果の理解
```
(105, 4) ← x_trainの行数と列数（105件が訓練用）
(45, 4)  ← x_testの行数と列数（45件がテスト用）
```
- 全データ150件のうち、105件が訓練用、45件がテスト用に分割
- 4つの特徴量（列）を使用

## ⚠️ よくある間違いと正しい方法

### ❌ 間違った評価方法
```python
# 訓練データで学習
model.fit(x_train, y_train)

# 同じ訓練データで評価（これはダメ！）
score = model.score(x_train, y_train)  # 見かけ上高い正解率
```

### ✅ 正しい評価方法
```python
# 訓練データで学習
model.fit(x_train, y_train)

# 別のテストデータで評価（これが正解！）
score = model.score(x_test, y_test)  # 真の性能
```

## 🤖 モデルの学習と評価プロセス

### 学習フェーズ
```python
model.fit(x_train, y_train)  # 訓練データでモデルを学習
```

### 評価フェーズ
```python
model.score(x_test, y_test)  # テストデータで正解率を計算
```

### 重要なポイント
- **学習に使ったデータとは別のデータ**で評価する
- ✅ **真の性能**を測定できる
- ✅ **過学習**を防げる
- ✅ **未知のデータ**への対応力が分かる

## 💾 モデルの保存

### なぜ保存が必要？
- 一度学習したモデルを再利用できる
- 学習に時間がかかる場合、毎回学習し直す必要がない
- 本番環境でモデルを使い回せる

### pickleを使った保存方法
```python
import pickle
with open('irismodel.pkl', 'wb') as f:
    pickle.dump(model, f)
```

## 🌳 決定木の内部構造分析

### 4.1 決定木の深さ（max_depth）
```
深さ1: 根ノード → 子ノード
深さ2: 根ノード → 子ノード → 孫ノード
```

**max_depth=2の意味:**
- 最大2階層まで分岐する
- 深すぎると過学習、浅すぎると性能不足
- バランスが重要

### 4.2 分岐条件の列番号（特徴量）
```python
model.tree_.feature  # どの特徴量で分岐するかの情報
```

**実行結果の解読:**
```
array([3, -2, 3, -2, -2])
```
- **3**: 4番目の特徴量で分岐（0から数えるため）
- **-2**: 分岐しない（リーフノード）

### 4.3 分岐条件のしきい値（tree_.threshold）

**threshold（しきい値）**は、各ノードで「Yes/No」を決める**基準値**

```python
model.tree_.threshold
```
**結果:**
```
array([0.275, -2., 0.69, -2., -2.])
```

**各値の意味:**
- **0.275**: ノード0での分岐基準値
- **-2**: 分岐しない（リーフノード）
- **0.69**: ノード2での分岐基準値

**分岐の仕組み:**
```
ノード番号0（花弁幅 ≤ 0.275）
    ├─ True → ノード1（分岐終了）
    └─ False → ノード2（花弁幅 ≤ 0.69）
                   ├─ True → ノード3（分岐終了）
                   └─ False → ノード4（分岐終了）
```

### 4.4 末端ノードと種類の紐付け（tree_.value）

**tree_.value**は各ノードに到達した**データの種類別の個数**を表示

```python
model.tree_.value[1]  # ノード番号1の結果
model.tree_.value[3]  # ノード番号3の結果
model.tree_.value[4]  # ノード番号4の結果
```

**結果:**
```
[[34, 0, 0]]    # ノード1: グループ0が34個、グループ1が0個、グループ2が0個
[0, 31, 6]]     # ノード3: グループ0が0個、グループ1が31個、グループ2が6個
[0, 1, 33]]     # ノード4: グループ0が0個、グループ1が1個、グループ2が33個
```

**実際の意味:**
- **ノード1**: 花弁幅≤0.275のデータは34個すべてが同じ種類（完全分類）
- **ノード3**: 花弁幅0.275〜0.69のデータは2種類混在（不完全分類）
- **ノード4**: 花弁幅>0.69のデータはほぼ1種類（ほぼ完全分類）

### 4.5 クラス名とグループ番号の対応

```python
model.classes_
```

**結果:**
```
array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])
```

**グループ番号の対応:**
- **グループ0**: Iris-setosa（セトサ種）
- **グループ1**: Iris-versicolor（バーシカラー種）
- **グループ2**: Iris-virginica（バージニカ種）

**決定木の分類結果:**
```
ノード1 → Iris-setosa（34個、100%純度）
ノード3 → Iris-versicolor主体（31個 vs 6個、約84%純度）
ノード4 → Iris-virginica主体（33個 vs 1個、約97%純度）
```

## 🎨 決定木の可視化（plot_tree）

### scikit-learnの新機能
**バージョン0.21以降**で`plot_tree`関数が追加され、外部ライブラリなしで決定木を描画可能

### 可視化コードの詳細
```python
# 特徴量の名前を日本語で設定
x_train.columns = ['gaku_nagasa', 'gaku_haba', 
                   'kaben_nagasa', 'kaben_haba']

# plot_tree関数をインポート
from sklearn.tree import plot_tree

# 決定木を描画
plot_tree(model, 
         feature_names = x_train.columns,  # 特徴量名を指定
         filled = True)                    # ノードを色付きで表示
```

### 描画結果の見方

#### ルートノード（最上位）
```
kaben_haba <= 0.275
gini = 0.664
samples = 105
value = [34, 32, 39]
```

**各項目の意味:**
- **kaben_haba <= 0.275**: 分岐条件（花弁幅≤0.275）
- **gini = 0.664**: ジニ不純度（0に近いほど純粋）
- **samples = 105**: このノードに含まれるデータ数
- **value = [34, 32, 39]**: 各クラスのデータ数

#### リーフノード（末端）
```
gini = 0.0
samples = 34
value = [34, 0, 0]
```
- **gini = 0.0**: 完全に純粋（1種類のみ）
- **samples = 34**: 34個のデータがこのノードに分類
- **value = [34, 0, 0]**: すべてがクラス0（Iris-setosa）

## 🧮 ジニ不純度の理解

### ジニ不純度とは
**データの混合度**を表す指標で、0〜0.5の値を取る

### 計算例
```python
# ノード1の場合: [34, 0, 0]
gini = 1 - (34/34)² - (0/34)² - (0/34)² = 1 - 1 = 0.0

# ルートノードの場合: [34, 32, 39]
gini = 1 - (34/105)² - (32/105)² - (39/105)² ≈ 0.664
```

### 解釈
- **gini = 0.0**: 完全に純粋（理想的）
- **gini = 0.5**: 最も混合している状態
- **値が小さいほど良い分類**

## 💡 実践的なアドバイス

### データ分割の注意点
- **test_size**: 通常0.2〜0.3（20%〜30%）
- **random_state**: 固定値を設定して再現性を保つ
- **データの偏り**: 分割後も各クラスが適切に含まれているか確認

### 適切な分割比率
- **一般的**: 訓練70% vs テスト30%
- **データが多い場合**: 訓練80% vs テスト20%
- **データが少ない場合**: 訓練60% vs テスト40%

### モデル評価の注意点
- **訓練データでの評価は禁物**: 必ずテストデータで評価
- **正解率だけでなく**: 他の指標（適合率、再現率など）も考慮
- **交差検証**: より信頼性の高い評価方法も存在

### 決定木の調整
- **max_depth**: 深すぎず浅すぎない適切な値を選択
- **可視化**: 分岐条件を理解して、モデルの妥当性を確認
- **特徴量の重要度**: どの特徴量が予測に重要かを分析

### 決定木の品質評価
1. **リーフノードのジニ不純度**をチェック
2. **各ノードのサンプル数**を確認
3. **分岐条件の妥当性**を検討

### モデルの改善指針
```python
# 深さを制限して過学習を防ぐ
model = DecisionTreeClassifier(max_depth=3)

# 最小サンプル数を設定
model = DecisionTreeClassifier(min_samples_leaf=5)
```

### 可視化のメリット
- **分岐ロジックが明確**になる
- **ドメイン知識との整合性**を確認できる
- **予測根拠を説明**しやすい
- **モデルの改善点**が見つけやすい

## 🔍 全体のワークフローまとめ

### ステップ1: データ準備
```python
# データを訓練用とテスト用に分割
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)
```

### ステップ2: モデル学習
```python
# 決定木モデルを訓練データで学習
model.fit(x_train, y_train)
```

### ステップ3: 性能評価
```python
# テストデータで正解率を計算
accuracy = model.score(x_test, y_test)
```

### ステップ4: モデル保存
```python
# 学習済みモデルをファイルに保存
pickle.dump(model, file)
```

### ステップ5: 内部構造分析
```python
print("分岐特徴量:", model.tree_.feature)
print("分岐しきい値:", model.tree_.threshold)
print("各ノードのデータ数:", model.tree_.value)
print("クラス名:", model.classes_)
```

### ステップ6: 可視化
```python
plot_tree(model, feature_names=feature_names, filled=True)
```

### ステップ7: 解釈と改善
- ジニ不純度が高いノードを特定
- 分岐条件の妥当性を評価
- 必要に応じてハイパーパラメータを調整

## 🎭 最終的なまとめ

機械学習の評価は「**カンニングしないテスト**」と同じです：

1. **学習フェーズ**: 訓練データでモデルを教育
2. **評価フェーズ**: 全く別のテストデータで実力測定
3. **結果**: 真の性能が分かり、過学習を防げる

この一連の流れを理解することで、**実際のサービスで使える信頼できるモデル**を構築できるようになります。決定木は「なぜその予測になったか」を明確に説明できる貴重な機械学習手法なので、内部構造を理解することで、より効果的に活用できます。